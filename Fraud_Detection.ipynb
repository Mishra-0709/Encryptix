{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3r9QnsNanRNyaqQzSWDTw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mishra-0709/C-program/blob/cat/Fraud_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the Data"
      ],
      "metadata": {
        "id": "HfNw9-4bNaxI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af0O2VDQNPLt",
        "outputId": "9563ce47-4076-47cf-e507-ea1d97403f82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0 trans_date_trans_time        cc_num  \\\n",
            "0           0   2020-06-21 12:14:25  2.291164e+15   \n",
            "1           1   2020-06-21 12:14:33  3.573030e+15   \n",
            "2           2   2020-06-21 12:14:53  3.598215e+15   \n",
            "3           3   2020-06-21 12:15:15  3.591920e+15   \n",
            "4           4   2020-06-21 12:15:17  3.526826e+15   \n",
            "\n",
            "                               merchant        category    amt   first  \\\n",
            "0                 fraud_Kirlin and Sons   personal_care   2.86    Jeff   \n",
            "1                  fraud_Sporer-Keebler   personal_care  29.84  Joanne   \n",
            "2  fraud_Swaniawski, Nitzsche and Welch  health_fitness  41.28  Ashley   \n",
            "3                     fraud_Haley Group        misc_pos  60.05   Brian   \n",
            "4                 fraud_Johnston-Casper          travel   3.19  Nathan   \n",
            "\n",
            "       last gender                       street  ...      lat      long  \\\n",
            "0   Elliott      M            351 Darlene Green  ...  33.9659  -80.9355   \n",
            "1  Williams      F             3638 Marsh Union  ...  40.3207 -110.4360   \n",
            "2     Lopez      F         9333 Valentine Point  ...  40.6729  -73.5365   \n",
            "3  Williams      M  32941 Krystal Mill Apt. 552  ...  28.5697  -80.8191   \n",
            "4    Massey      M     5783 Evan Roads Apt. 465  ...  44.2529  -85.0170   \n",
            "\n",
            "   city_pop                     job         dob  \\\n",
            "0    333497     Mechanical engineer  1968-03-19   \n",
            "1       302  Sales professional, IT  1990-01-17   \n",
            "2     34496       Librarian, public  1970-10-21   \n",
            "3     54767            Set designer  1987-07-25   \n",
            "4      1126      Furniture designer  1955-07-06   \n",
            "\n",
            "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
            "0  2da90c7d74bd46a0caf3777415b3ebd3  1371816865  33.986391  -81.200714   \n",
            "1  324cc204407e99f51b0d6ca0055005e7  1371816873  39.450498 -109.960431   \n",
            "2  c81755dbbbea9d5c77f094348a7579be  1371816893  40.495810  -74.196111   \n",
            "3  2159175b9efe66dc301f149d3d5abf8c  1371816915  28.812398  -80.883061   \n",
            "4  57ff021bd3f328f8738bb535c302a31b  1371816917  44.959148  -85.884734   \n",
            "\n",
            "   is_fraud  \n",
            "0         0  \n",
            "1         0  \n",
            "2         0  \n",
            "3         0  \n",
            "4         0  \n",
            "\n",
            "[5 rows x 23 columns]\n",
            "Unnamed: 0               0\n",
            "trans_date_trans_time    0\n",
            "cc_num                   0\n",
            "merchant                 0\n",
            "category                 0\n",
            "amt                      0\n",
            "first                    0\n",
            "last                     0\n",
            "gender                   0\n",
            "street                   0\n",
            "city                     0\n",
            "state                    0\n",
            "zip                      0\n",
            "lat                      0\n",
            "long                     0\n",
            "city_pop                 0\n",
            "job                      0\n",
            "dob                      0\n",
            "trans_num                0\n",
            "unix_time                0\n",
            "merch_lat                0\n",
            "merch_long               0\n",
            "is_fraud                 0\n",
            "dtype: int64\n",
            "   Unnamed: 0 trans_date_trans_time                              merchant  \\\n",
            "0           0   2020-06-21 12:14:25                 fraud_Kirlin and Sons   \n",
            "1           1   2020-06-21 12:14:33                  fraud_Sporer-Keebler   \n",
            "2           2   2020-06-21 12:14:53  fraud_Swaniawski, Nitzsche and Welch   \n",
            "3           3   2020-06-21 12:15:15                     fraud_Haley Group   \n",
            "4           4   2020-06-21 12:15:17                 fraud_Johnston-Casper   \n",
            "\n",
            "         category    amt gender  city_pop        dob  is_fraud  \n",
            "0   personal_care   2.86      M    333497 1968-03-19         0  \n",
            "1   personal_care  29.84      F       302 1990-01-17         0  \n",
            "2  health_fitness  41.28      F     34496 1970-10-21         0  \n",
            "3        misc_pos  60.05      M     54767 1987-07-25         0  \n",
            "4          travel   3.19      M      1126 1955-07-06         0  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('fraudTest.csv')\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "print(df.head())\n",
        "\n",
        "# Check for missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Convert 'trans_date_trans_time' and 'dob' to datetime\n",
        "df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
        "df['dob'] = pd.to_datetime(df['dob'], errors='coerce')\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df.drop(['cc_num', 'first', 'last', 'street', 'city', 'state',\n",
        "         'zip', 'lat', 'long', 'job', 'trans_num', 'unix_time', 'merch_lat', 'merch_long'], axis=1, inplace=True)\n",
        "\n",
        "# Check the cleaned dataframe\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Engineering"
      ],
      "metadata": {
        "id": "1n7AjBiLNh7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features from datetime columns\n",
        "df['trans_year'] = df['trans_date_trans_time'].dt.year\n",
        "df['trans_month'] = df['trans_date_trans_time'].dt.month\n",
        "df['trans_day'] = df['trans_date_trans_time'].dt.day\n",
        "df['age'] = df['trans_date_trans_time'].dt.year - df['dob'].dt.year\n",
        "\n",
        "# Drop the processed datetime columns\n",
        "df.drop(['trans_date_trans_time', 'dob'], axis=1, inplace=True)\n",
        "\n",
        "# Handle missing values for 'age'\n",
        "df['age'].fillna(df['age'].median(), inplace=True)\n",
        "\n",
        "# Check the dataframe after feature engineering\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXkylEqENlHu",
        "outputId": "9a8e38bb-5680-432e-ef59-c4c9bfaac795"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0                              merchant        category    amt  \\\n",
            "0           0                 fraud_Kirlin and Sons   personal_care   2.86   \n",
            "1           1                  fraud_Sporer-Keebler   personal_care  29.84   \n",
            "2           2  fraud_Swaniawski, Nitzsche and Welch  health_fitness  41.28   \n",
            "3           3                     fraud_Haley Group        misc_pos  60.05   \n",
            "4           4                 fraud_Johnston-Casper          travel   3.19   \n",
            "\n",
            "  gender  city_pop  is_fraud  trans_year  trans_month  trans_day  age  \n",
            "0      M    333497         0        2020            6         21   52  \n",
            "1      F       302         0        2020            6         21   30  \n",
            "2      F     34496         0        2020            6         21   50  \n",
            "3      M     54767         0        2020            6         21   33  \n",
            "4      M      1126         0        2020            6         21   65  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the Data"
      ],
      "metadata": {
        "id": "mbQwamwXNsOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Features and target variable\n",
        "X = df.drop('is_fraud', axis=1)\n",
        "y = df['is_fraud']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Check the shapes of the datasets\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-rxQArINszi",
        "outputId": "b5b9ba4b-155f-4268-bbd8-f1d8a4079833"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(45874, 10) (19661, 10) (45874,) (19661,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Building"
      ],
      "metadata": {
        "id": "cgX3nDSYNuip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Preprocessing for numerical and categorical features\n",
        "numeric_features = ['amt', 'city_pop', 'trans_year', 'trans_month', 'trans_day', 'age']\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "categorical_features = ['merchant', 'category', 'gender']\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# Logistic Regression Model\n",
        "clf_lr = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                         ('classifier', LogisticRegression(max_iter=1000))])\n",
        "\n",
        "# Decision Tree Model\n",
        "clf_dt = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                         ('classifier', DecisionTreeClassifier(random_state=42))])\n",
        "\n",
        "# Random Forest Model\n",
        "clf_rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                         ('classifier', RandomForestClassifier(random_state=42))])"
      ],
      "metadata": {
        "id": "9t4M0jj9Nwbv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation"
      ],
      "metadata": {
        "id": "xKLorvJTNyLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Train and evaluate models\n",
        "models = {'Logistic Regression': clf_lr, 'Decision Tree': clf_dt, 'Random Forest': clf_rf}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"Model: {name}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Assuming Random Forest performed the best\n",
        "best_model = clf_rf\n",
        "y_pred_best = best_model.predict(X_test)\n",
        "\n",
        "# Confusion Matrix for the best model\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_best)\n",
        "\n",
        "# Plotting the confusion matrix as a heatmap\n",
        "plt.figure(figsize=(10, 7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "id": "8gcTpG3-QNCF",
        "outputId": "2480bc4a-7d28-4fc1-da82-bfc8a020a028"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Logistic Regression\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     19565\n",
            "           1       0.00      0.00      0.00        96\n",
            "\n",
            "    accuracy                           0.99     19661\n",
            "   macro avg       0.50      0.50      0.50     19661\n",
            "weighted avg       0.99      0.99      0.99     19661\n",
            "\n",
            "[[19550    15]\n",
            " [   96     0]]\n",
            "\n",
            "\n",
            "Model: Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     19565\n",
            "           1       0.54      0.46      0.50        96\n",
            "\n",
            "    accuracy                           1.00     19661\n",
            "   macro avg       0.77      0.73      0.75     19661\n",
            "weighted avg       1.00      1.00      1.00     19661\n",
            "\n",
            "[[19528    37]\n",
            " [   52    44]]\n",
            "\n",
            "\n",
            "Model: Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     19565\n",
            "           1       0.94      0.17      0.28        96\n",
            "\n",
            "    accuracy                           1.00     19661\n",
            "   macro avg       0.97      0.58      0.64     19661\n",
            "weighted avg       1.00      1.00      0.99     19661\n",
            "\n",
            "[[19564     1]\n",
            " [   80    16]]\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 0 Axes>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}